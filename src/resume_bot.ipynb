{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33583d94-e35c-49bf-9bd9-cc4702b4573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import itertools\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_precision, context_recall, Faithfulness\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb1a694-ee9b-493a-8dc2-6a5dcffc6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../pdf/Mateo Wheeler Resume v2.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de16b3c-6566-41d7-b78c-65a3a2167774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6828"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b2137c-9ae8-445e-830f-4ca8ebb62f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "#Split and chunk the data\n",
    "chunk_size = 150\n",
    "chunk_overlap = 75\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Add the chunks to vector database, which uses nomic for model embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "                                    documents=chunks, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "                                    collection_name=\"local-rag\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e777e083-731e-4c6c-8e15-20455cd84035",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a recruiter, you need to evaluate if a candidate is a good fit for a role. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6917f39f-b4b3-4453-a07b-47d76e24bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy company_description and job_description from LinkedIn job posts\n",
    "company_description = \"\"\"Since its founding in 1993, NVIDIA (NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling the creation of the metaverse. NVIDIA is now a full-stack computing company with data-center-scale offerings that are reshaping industry.\n",
    "\"\"\"\n",
    "\n",
    "job_description = \"\"\"Professional, long-term experience as a Data Scientist (focused on AI/ML) developing/supporting business facing projects.\n",
    "8+ years of experience, including 5+ years of demonstrated ability in business-focused AI and Data Science. Job scope can be adjusted to accommodate more experienced candidates.\n",
    "BS/MS/PhD or equivalent experience in Computer Science, Data Science, Electrical/Computer Engineering, Physics, Mathematics, other Engineering fields. Technical Master’s or Ph.D. with finance or business background is preferred.\n",
    "Data Science project management, driving projects and coordinating across multidisciplinary teams inside the organization.\n",
    "Strong technical skills, with a proven history of designing, validating, deploying, and maintaining data science models using Python, SQL, & Databricks (or similar).\n",
    "Excellent communication skills, with the ability to maintain good documentation and present projects to technical and business partners.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a19eaae-15d9-485b-bb05-3c3c509f3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can assess the candidate's qualifications for the Data Scientist role at NVIDIA.\n",
      "\n",
      "The candidate has 5+ years of experience in business-focused AI and Data Science, which meets the minimum requirement. They have a strong technical background in Python, PySpark, SQL, SAS, and other machine learning libraries, as well as experience with data visualization tools like NLTK, Spacy, and Word2Vec.\n",
      "\n",
      "The candidate has also demonstrated expertise in various domains, including Federal, Telecommunications, Real Estate, SaaS, Subscription Services, and Meal Kit industries. This suggests that they have a broad understanding of different business applications and can adapt to various projects.\n",
      "\n",
      "Furthermore, the candidate has experience working with Agile methodologies (Atlassian Jira & Confluence), managing teams (hired and managed 3 direct reports), and facilitating daily and monthly updates to SaaS products. These skills are valuable for data science project management and coordination across multidisciplinary teams.\n",
      "\n",
      "The candidate's work experience includes:\n",
      "\n",
      "* Senior Data Scientist at HelloFresh (2021-2025), where they worked on projects like anomaly detection, data scraping systems, and model performance tracking.\n",
      "* Experience with various machine learning libraries, including TensorFlow, PyTorch, scikit-learn, Prophet, Nixtla TimeGPT, Statsmodels, Sagemaker DeepAR, Catboost, sklearn, NLTK, Spacy, Word2Vec, SBERT/HuggingFace, OpenAl, Langchain, YOLO, GCP AutoML, Databricks MLOps.\n",
      "\n",
      "Overall, the candidate appears to have a strong technical background, experience working with various projects and domains, and valuable soft skills for data science project management.\n"
     ]
    }
   ],
   "source": [
    "context = f\"Role: you are a recruiter for {company_description}. The job position requirements are the following:\\\n",
    "            {job_description}\\\n",
    "        \"\n",
    "\n",
    "q = \"Can you evaluate the candidate in this resume document for the role provided?\"\n",
    "\n",
    "response = chain.invoke(input={'context': context, 'question': q})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b0d38",
   "metadata": {},
   "source": [
    "#### Evaluate the response using Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e42b5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a job recruiter, you want to understand a candidate's resume, but not specific to a job position. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7a0810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the number of years of experience, we need to analyze the dates provided for each position.\n",
      "\n",
      "1. PricewaterhouseCoopers / Associate (2010-2016): 6 years\n",
      "2. Masters of Science, Statistics (2007-2009): 2 years\n",
      "3. Hellofresh / Senior Data Scientist (2021-2025): 4 years\n",
      "\n",
      "Adding up these periods: 6 + 2 + 4 = 12 years.\n",
      "\n",
      "So, the candidate has a total of 12 years of experience.\n"
     ]
    }
   ],
   "source": [
    "context0 = f\"Role: you are a generic recruiter reading a candidate's resume.\"\n",
    "q0 = \"Based on the dates listed for each position, how many years of experience does this candidate have?\"\n",
    "\n",
    "response0 = chain.invoke(input={'context': context0, 'question': q0})\n",
    "print(response0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33f1c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the candidate has experience with the following machine learning libraries:\n",
      "\n",
      "1. TensorFlow\n",
      "2. PyTorch\n",
      "3. scikit-learn\n",
      "4. Prophet\n",
      "5. Nixtla TimeGPT\n",
      "6. Statsmodels\n",
      "7. Sagemaker DeepAR\n",
      "8. Catboost\n",
      "9. sklearn\n",
      "10. NLTK\n",
      "11. Spacy\n",
      "12. Word2Vec\n",
      "\n",
      "Additionally, the candidate has experience with various other machine learning models and frameworks, including:\n",
      "\n",
      "* SBERT/HuggingFace\n",
      "* OpenAl\n",
      "* Langchain\n",
      "* YOLO\n",
      "* GCP AutoML\n",
      "* Databricks MLOps\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Based on this resume, what machine libraries is the candidate experienced with?\"\n",
    "\n",
    "response1 = chain.invoke(input={'context': context0, 'question': q1})\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85115a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": [\n",
      "        \"Based on the dates listed for each position, how many years of experience does this candidate have?\"\n",
      "    ],\n",
      "    \"answer\": [\n",
      "        \"To calculate the number of years of experience, we need to analyze the dates provided for each position.1. PricewaterhouseCoopers / Associate (2010-2016): 6 years2. Masters of Science, Statistics (2007-2009): 2 years3. Hellofresh / Senior Data Scientist (2021-2025): 4 yearsAdding up these periods: 6 + 2 + 4 = 12 years.So, the candidate has a total of 12 years of experience.\"\n",
      "    ],\n",
      "    \"contexts\": [\n",
      "        [\n",
      "            \"Role: you are a generic recruiter reading a candidate's resume.\"\n",
      "        ]\n",
      "    ],\n",
      "    \"ground_truth\": [\n",
      "        \"The candidate has a total of 18.5 years of experience.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_samples = {\n",
    "    'question': [\n",
    "         q0, \n",
    "         #q1\n",
    "    ],\n",
    "    'answer': [\n",
    "         response0.replace(\"\\n\", \"\"), \n",
    "         #response1.replace(\"\\n\", \"\")\n",
    "\n",
    "    ],\n",
    "    'contexts': [\n",
    "        [\n",
    "            context0\n",
    "        ],\n",
    "        #[\n",
    "        #    context0\n",
    "        #]\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "        'The candidate has a total of 18.5 years of experience.',\n",
    "        #'Tensorflow, PyTorch, scikit-learn, Prophet, Nixtla TimeGPT, Statsmodels, Sagemaker DeepAR, Catboost, sklearn, NLTK, Spacy, Word2Vec, SBERT/HuggingFace, OpenAI, Langchain, YOLO,  Deep learning, Reinforcement Learning, RAG Systems'\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "json_formatted_string = json.dumps(data_samples, indent=4)\n",
    "print(json_formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d88668c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Ensure deterministic output for evaluation\n",
    "llm_eval = ChatOllama(model=local_llm, temperature=0)\n",
    "evaluator_llm = LangchainLLMWrapper(llm_eval)\n",
    "evaluator_embed = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "\n",
    "# Test if embeddings wrapper works\n",
    "try:\n",
    "    test_embedding = evaluator_embed.embed_query(\"test text\")\n",
    "    print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Embeddings wrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dfa799e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM test response: <coroutine object BaseRagasLLM.generate at 0x162578280>\n"
     ]
    }
   ],
   "source": [
    "# Test if the LLM wrapper works correctly\n",
    "test_prompt = \"Rate this answer's faithfulness on a scale of 1-5: 'The sky is blue'\"\n",
    "try:\n",
    "    response = evaluator_llm.generate([test_prompt])\n",
    "    print(f\"LLM test response: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM wrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63694f5184d948cab99b871b20462d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/output_parsers/json.py:82\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/utils/json.py:150\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    149\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/utils/json.py:166\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/utils/json.py:123\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m evaluator_embed = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Evaluate using Ragas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_recall\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_wait\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_tenacity\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/evaluation.py:318\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_group_cm.ended:\n\u001b[32m    316\u001b[39m         evaluation_rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# evalution run was successful\u001b[39;00m\n\u001b[32m    321\u001b[39m     \u001b[38;5;66;03m# now lets process the results\u001b[39;00m\n\u001b[32m    322\u001b[39m     cost_cb = ragas_callbacks[\u001b[33m\"\u001b[39m\u001b[33mcost_cb\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcost_cb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ragas_callbacks \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:141\u001b[39m, in \u001b[36mExecutor._process_jobs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    137\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jobs),\n\u001b[32m    138\u001b[39m         desc=\u001b[38;5;28mself\u001b[39m.desc,\n\u001b[32m    139\u001b[39m         disable=\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    140\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m internal_pbar:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    142\u001b[39m             \u001b[38;5;28mself\u001b[39m.jobs, internal_pbar, results, max_workers\n\u001b[32m    143\u001b[39m         )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_coroutines(\n\u001b[32m    146\u001b[39m         \u001b[38;5;28mself\u001b[39m.jobs, \u001b[38;5;28mself\u001b[39m.pbar, results, max_workers\n\u001b[32m    147\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:191\u001b[39m, in \u001b[36mExecutor._process_coroutines\u001b[39m\u001b[34m(self, jobs, pbar, results, max_workers)\u001b[39m\n\u001b[32m    189\u001b[39m coroutines = [afunc(*args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m afunc, args, kwargs, _ \u001b[38;5;129;01min\u001b[39;00m jobs]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m as_completed(coroutines, max_workers):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    192\u001b[39m     results.append(result)\n\u001b[32m    193\u001b[39m     pbar.update(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:634\u001b[39m, in \u001b[36m_AsCompletedIterator._wait_for_one\u001b[39m\u001b[34m(self, resolve)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    632\u001b[39m     \u001b[38;5;66;03m# Dummy value from _handle_timeout().\u001b[39;00m\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.TimeoutError\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m resolve \u001b[38;5;28;01melse\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:48\u001b[39m, in \u001b[36mas_completed.<locals>.sema_coro\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msema_coro\u001b[39m(coro):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:100\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raise_exceptions:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m         exec_name = \u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/executor.py:96\u001b[39m, in \u001b[36mExecutor.wrap_callable_with_index.<locals>.wrapped_callable_async\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped_callable_async\u001b[39m(\n\u001b[32m     93\u001b[39m     *args, **kwargs\n\u001b[32m     94\u001b[39m ) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, t.Callable | \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(*args, **kwargs)\n\u001b[32m     97\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m counter, result\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/base.py:541\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n\u001b[32m    540\u001b[39m         rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/base.py:534\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    527\u001b[39m rm, group_cm = new_group(\n\u001b[32m    528\u001b[39m     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    529\u001b[39m     inputs=sample.to_dict(),\n\u001b[32m    530\u001b[39m     callbacks=callbacks,\n\u001b[32m    531\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.METRIC},\n\u001b[32m    532\u001b[39m )\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     score = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    535\u001b[39m         \u001b[38;5;28mself\u001b[39m._single_turn_ascore(sample=sample, callbacks=group_cm),\n\u001b[32m    536\u001b[39m         timeout=timeout,\n\u001b[32m    537\u001b[39m     )\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:507\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/_context_precision.py:260\u001b[39m, in \u001b[36mContextPrecision._single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_single_turn_ascore\u001b[39m(\n\u001b[32m    258\u001b[39m     \u001b[38;5;28mself\u001b[39m, sample: SingleTurnSample, callbacks: Callbacks\n\u001b[32m    259\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._single_turn_ascore(sample, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/_context_precision.py:140\u001b[39m, in \u001b[36mLLMContextPrecisionWithReference._single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_single_turn_ascore\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m, sample: SingleTurnSample, callbacks: Callbacks\n\u001b[32m    138\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    139\u001b[39m     row = sample.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/_context_precision.py:266\u001b[39m, in \u001b[36mContextPrecision._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\n\u001b[32m    263\u001b[39m     since=\u001b[33m\"\u001b[39m\u001b[33m0.2\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m0.3\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33mLLMContextPrecisionWithReference\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    264\u001b[39m )\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ascore\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: t.Dict, callbacks: Callbacks) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/metrics/_context_precision.py:153\u001b[39m, in \u001b[36mLLMContextPrecisionWithReference._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    150\u001b[39m responses = []\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m retrieved_contexts:\n\u001b[32m    152\u001b[39m     verdicts: t.List[Verification] = (\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.context_precision_prompt.generate_multiple(\n\u001b[32m    154\u001b[39m             data=QAC(\n\u001b[32m    155\u001b[39m                 question=user_input,\n\u001b[32m    156\u001b[39m                 context=context,\n\u001b[32m    157\u001b[39m                 answer=reference,\n\u001b[32m    158\u001b[39m             ),\n\u001b[32m    159\u001b[39m             llm=\u001b[38;5;28mself\u001b[39m.llm,\n\u001b[32m    160\u001b[39m             callbacks=callbacks,\n\u001b[32m    161\u001b[39m         )\n\u001b[32m    162\u001b[39m     )\n\u001b[32m    164\u001b[39m     responses.append([result.model_dump() \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m verdicts])\n\u001b[32m    166\u001b[39m answers = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:203\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    201\u001b[39m output_string = resp.generations[\u001b[32m0\u001b[39m][i].text\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     answer = \u001b[38;5;28;01mawait\u001b[39;00m parser.parse_output_string(\n\u001b[32m    204\u001b[39m         output_string=output_string,\n\u001b[32m    205\u001b[39m         prompt_value=prompt_value,\n\u001b[32m    206\u001b[39m         llm=llm,\n\u001b[32m    207\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    208\u001b[39m         retries_left=retries_left,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    210\u001b[39m     processed_output = \u001b[38;5;28mself\u001b[39m.process_output(answer, data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    211\u001b[39m     output_models.append(processed_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:411\u001b[39m, in \u001b[36mRagasOutputParser.parse_output_string\u001b[39m\u001b[34m(self, output_string, prompt_value, llm, callbacks, retries_left)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retries_left != \u001b[32m0\u001b[39m:\n\u001b[32m    406\u001b[39m     retry_rm, retry_cb = new_group(\n\u001b[32m    407\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mfix_output_format\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    408\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33moutput_string\u001b[39m\u001b[33m\"\u001b[39m: output_string},\n\u001b[32m    409\u001b[39m         callbacks=callbacks,\n\u001b[32m    410\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     fixed_output_string = \u001b[38;5;28;01mawait\u001b[39;00m fix_output_format_prompt.generate(\n\u001b[32m    412\u001b[39m         llm=llm,\n\u001b[32m    413\u001b[39m         data=OutputStringAndPrompt(\n\u001b[32m    414\u001b[39m             output_string=output_string,\n\u001b[32m    415\u001b[39m             prompt_value=prompt_value.to_string(),\n\u001b[32m    416\u001b[39m         ),\n\u001b[32m    417\u001b[39m         callbacks=retry_cb,\n\u001b[32m    418\u001b[39m         retries_left=retries_left - \u001b[32m1\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m    420\u001b[39m     retry_rm.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33mfixed_output_string\u001b[39m\u001b[33m\"\u001b[39m: fixed_output_string})\n\u001b[32m    421\u001b[39m     result = \u001b[38;5;28msuper\u001b[39m().parse(fixed_output_string.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:129\u001b[39m, in \u001b[36mPydanticPrompt.generate\u001b[39m\u001b[34m(self, llm, data, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    126\u001b[39m callbacks = callbacks \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# this is just a special case of generate_multiple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m output_single = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate_multiple(\n\u001b[32m    130\u001b[39m     llm=llm,\n\u001b[32m    131\u001b[39m     data=data,\n\u001b[32m    132\u001b[39m     n=\u001b[32m1\u001b[39m,\n\u001b[32m    133\u001b[39m     temperature=temperature,\n\u001b[32m    134\u001b[39m     stop=stop,\n\u001b[32m    135\u001b[39m     callbacks=callbacks,\n\u001b[32m    136\u001b[39m     retries_left=retries_left,\n\u001b[32m    137\u001b[39m )\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output_single[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:203\u001b[39m, in \u001b[36mPydanticPrompt.generate_multiple\u001b[39m\u001b[34m(self, llm, data, n, temperature, stop, callbacks, retries_left)\u001b[39m\n\u001b[32m    201\u001b[39m output_string = resp.generations[\u001b[32m0\u001b[39m][i].text\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     answer = \u001b[38;5;28;01mawait\u001b[39;00m parser.parse_output_string(\n\u001b[32m    204\u001b[39m         output_string=output_string,\n\u001b[32m    205\u001b[39m         prompt_value=prompt_value,\n\u001b[32m    206\u001b[39m         llm=llm,\n\u001b[32m    207\u001b[39m         callbacks=prompt_cb,\n\u001b[32m    208\u001b[39m         retries_left=retries_left,\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    210\u001b[39m     processed_output = \u001b[38;5;28mself\u001b[39m.process_output(answer, data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    211\u001b[39m     output_models.append(processed_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py:421\u001b[39m, in \u001b[36mRagasOutputParser.parse_output_string\u001b[39m\u001b[34m(self, output_string, prompt_value, llm, callbacks, retries_left)\u001b[39m\n\u001b[32m    411\u001b[39m     fixed_output_string = \u001b[38;5;28;01mawait\u001b[39;00m fix_output_format_prompt.generate(\n\u001b[32m    412\u001b[39m         llm=llm,\n\u001b[32m    413\u001b[39m         data=OutputStringAndPrompt(\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m         retries_left=retries_left - \u001b[32m1\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m    420\u001b[39m     retry_rm.on_chain_end({\u001b[33m\"\u001b[39m\u001b[33mfixed_output_string\u001b[39m\u001b[33m\"\u001b[39m: fixed_output_string})\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_output_string\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RagasOutputParserException()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/output_parsers/pydantic.py:77\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> TBaseModel:\n\u001b[32m     69\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     70\u001b[39m \n\u001b[32m     71\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m \u001b[33;03m        The parsed pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/output_parsers/json.py:96\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m     88\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     89\u001b[39m \n\u001b[32m     90\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m        The parsed JSON object.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/output_parsers/pydantic.py:61\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the result of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Documents mateos-macbook-air-m1/py-projects/pdf-rag/rag/lib/python3.13/site-packages/langchain_core/output_parsers/json.py:85\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     84\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: \nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate using Ragas\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        faithfulness\n",
    "    ],\n",
    "    #     context_precision,\n",
    "    #     faithfulness,\n",
    "    #     answer_relevancy,\n",
    "    #     context_recall\n",
    "    # ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embed,\n",
    "    run_config=RunConfig(timeout=300, \n",
    "                         max_retries=3, # Reduce retries initially\n",
    "                         max_wait=300, \n",
    "                         log_tenacity=False),\n",
    "    raise_exceptions=False # Don't stop on first error\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33424c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
