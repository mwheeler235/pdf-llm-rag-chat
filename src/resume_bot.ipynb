{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33583d94-e35c-49bf-9bd9-cc4702b4573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb1a694-ee9b-493a-8dc2-6a5dcffc6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../pdf/Mateo Wheeler Resume v2.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de16b3c-6566-41d7-b78c-65a3a2167774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6828"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b2137c-9ae8-445e-830f-4ca8ebb62f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "#Split and chunk the data\n",
    "chunk_size = 150\n",
    "chunk_overlap = 75\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Add the chunks to vector database, which uses nomic for model embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "                                    documents=chunks, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "                                    collection_name=\"local-rag\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e777e083-731e-4c6c-8e15-20455cd84035",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a recruiter, you need to evaluate if a candidate is a good fit for a role. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6917f39f-b4b3-4453-a07b-47d76e24bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy company_description and job_description from LinkedIn job posts\n",
    "company_description = \"\"\"Since its founding in 1993, NVIDIA (NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling the creation of the metaverse. NVIDIA is now a full-stack computing company with data-center-scale offerings that are reshaping industry.\n",
    "\"\"\"\n",
    "\n",
    "job_description = \"\"\"Professional, long-term experience as a Data Scientist (focused on AI/ML) developing/supporting business facing projects.\n",
    "8+ years of experience, including 5+ years of demonstrated ability in business-focused AI and Data Science. Job scope can be adjusted to accommodate more experienced candidates.\n",
    "BS/MS/PhD or equivalent experience in Computer Science, Data Science, Electrical/Computer Engineering, Physics, Mathematics, other Engineering fields. Technical Master’s or Ph.D. with finance or business background is preferred.\n",
    "Data Science project management, driving projects and coordinating across multidisciplinary teams inside the organization.\n",
    "Strong technical skills, with a proven history of designing, validating, deploying, and maintaining data science models using Python, SQL, & Databricks (or similar).\n",
    "Excellent communication skills, with the ability to maintain good documentation and present projects to technical and business partners.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a19eaae-15d9-485b-bb05-3c3c509f3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can evaluate the candidate's qualifications for the Data Scientist role at NVIDIA.\n",
      "\n",
      "The candidate has a background as a Senior Data Scientist at Hellofresh from November 2021 to April 2025. In this role, they likely developed and supported business-facing projects involving AI/ML, which aligns with the job requirements.\n",
      "\n",
      "According to the resume document, the candidate has:\n",
      "\n",
      "* Experience in pre-trained neural networks (SBERT, transfer learning) for NLP topic modeling\n",
      "* Familiarity with NLTK, sklearn, UMAP for data analysis\n",
      "* Experience in project management using Agile Methodology, Atlassian Jira & Confluence, and People Management tools\n",
      "* Strong technical skills in Python, SQL, and Databricks\n",
      "* Excellent communication skills\n",
      "\n",
      "The candidate also has a strong educational background, including a Bachelor's/Master's/PhD degree or equivalent experience in Computer Science, Data Science, Electrical/Computer Engineering, Physics, Mathematics, or other Engineering fields.\n",
      "\n",
      "While the candidate does not explicitly mention specific experience with NVIDIA technology or a metaverse-related project, their overall skills and experience align well with the job requirements. However, it is essential to consider additional factors, such as the candidate's fit with the company culture and team, during the interview process.\n"
     ]
    }
   ],
   "source": [
    "context = f\"Role: you are a recruiter for {company_description}. The job position requirements are the following:\\\n",
    "            {job_description}\\\n",
    "        \"\n",
    "\n",
    "q = \"Can you evaluate the candidate in this resume document for the role provided?\"\n",
    "\n",
    "response = chain.invoke(input={'context': context, 'question': q})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
