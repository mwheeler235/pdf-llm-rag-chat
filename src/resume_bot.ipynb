{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33583d94-e35c-49bf-9bd9-cc4702b4573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import itertools\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_precision, context_recall, answer_similarity\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from datasets import Dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb1a694-ee9b-493a-8dc2-6a5dcffc6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../pdf/Mateo Wheeler Resume v2.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de16b3c-6566-41d7-b78c-65a3a2167774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6828"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b2137c-9ae8-445e-830f-4ca8ebb62f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "#Split and chunk the data\n",
    "chunk_size = 150\n",
    "chunk_overlap = 75\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Add the chunks to vector database, which uses nomic for model embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "                                    documents=chunks, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "                                    collection_name=\"local-rag\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e777e083-731e-4c6c-8e15-20455cd84035",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a recruiter, you need to evaluate if a candidate is a good fit for a role. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6917f39f-b4b3-4453-a07b-47d76e24bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy company_description and job_description from LinkedIn job posts\n",
    "company_description = \"\"\"Since its founding in 1993, NVIDIA (NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling the creation of the metaverse. NVIDIA is now a full-stack computing company with data-center-scale offerings that are reshaping industry.\n",
    "\"\"\"\n",
    "\n",
    "job_description = \"\"\"Professional, long-term experience as a Data Scientist (focused on AI/ML) developing/supporting business facing projects.\n",
    "8+ years of experience, including 5+ years of demonstrated ability in business-focused AI and Data Science. Job scope can be adjusted to accommodate more experienced candidates.\n",
    "BS/MS/PhD or equivalent experience in Computer Science, Data Science, Electrical/Computer Engineering, Physics, Mathematics, other Engineering fields. Technical Master’s or Ph.D. with finance or business background is preferred.\n",
    "Data Science project management, driving projects and coordinating across multidisciplinary teams inside the organization.\n",
    "Strong technical skills, with a proven history of designing, validating, deploying, and maintaining data science models using Python, SQL, & Databricks (or similar).\n",
    "Excellent communication skills, with the ability to maintain good documentation and present projects to technical and business partners.\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a19eaae-15d9-485b-bb05-3c3c509f3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can assess the candidate's qualifications for the Data Scientist role at NVIDIA.\n",
      "\n",
      "The candidate has 5+ years of experience in business-focused AI and Data Science, which meets the minimum requirement. They have a strong technical background in Python, PySpark, SQL, SAS, and other machine learning libraries, as well as experience with data visualization tools like NLTK, Spacy, and Word2Vec.\n",
      "\n",
      "The candidate has also demonstrated expertise in various domains, including Federal, Telecommunications, Real Estate, SaaS, Subscription Services, and Meal Kit industries. This suggests that they have a broad understanding of different business applications and can adapt to various projects.\n",
      "\n",
      "Furthermore, the candidate has experience working with Agile methodologies (Atlassian Jira & Confluence), managing teams (hired and managed 3 direct reports), and facilitating daily and monthly updates to SaaS products. These skills are valuable for data science project management and coordination across multidisciplinary teams.\n",
      "\n",
      "The candidate's work experience includes:\n",
      "\n",
      "* Senior Data Scientist at HelloFresh (2021-2025), where they worked on projects like anomaly detection, data scraping systems, and model performance tracking.\n",
      "* Experience with various machine learning libraries, including TensorFlow, PyTorch, scikit-learn, Prophet, Nixtla TimeGPT, Statsmodels, Sagemaker DeepAR, Catboost, sklearn, NLTK, Spacy, Word2Vec, SBERT/HuggingFace, OpenAl, Langchain, YOLO, GCP AutoML, Databricks MLOps.\n",
      "\n",
      "Overall, the candidate appears to have a strong technical background, experience working with various projects and domains, and valuable soft skills for data science project management.\n"
     ]
    }
   ],
   "source": [
    "context = f\"Role: you are a recruiter for {company_description}. The job position requirements are the following:\\\n",
    "            {job_description}\\\n",
    "        \"\n",
    "\n",
    "q = \"Can you evaluate the candidate in this resume document for the role provided?\"\n",
    "\n",
    "response = chain.invoke(input={'context': context, 'question': q})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4b0d38",
   "metadata": {},
   "source": [
    "#### Evaluate the response using Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e42b5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a job recruiter, you want to understand a candidate's resume, but not specific to a job position. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7a0810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the number of years of experience, we need to analyze the dates provided for each position.\n",
      "\n",
      "1. PricewaterhouseCoopers / Associate (2010-2016): 6 years\n",
      "2. Masters of Science, Statistics (2007-2009): 2 years\n",
      "3. Hellofresh / Senior Data Scientist (2021-2025): 4 years\n",
      "\n",
      "Adding up these periods: 6 + 2 + 4 = 12 years.\n",
      "\n",
      "So, the candidate has a total of 12 years of experience.\n"
     ]
    }
   ],
   "source": [
    "context0 = f\"Role: you are a generic recruiter reading a candidate's resume.\"\n",
    "q0 = \"Based on the dates listed for each position, how many years of experience does this candidate have?\"\n",
    "\n",
    "response0 = chain.invoke(input={'context': context0, 'question': q0})\n",
    "print(response0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33f1c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the candidate has experience with the following machine learning libraries:\n",
      "\n",
      "1. TensorFlow\n",
      "2. PyTorch\n",
      "3. scikit-learn\n",
      "4. Prophet\n",
      "5. Nixtla TimeGPT\n",
      "6. Statsmodels\n",
      "7. Sagemaker DeepAR\n",
      "8. Catboost\n",
      "9. sklearn\n",
      "10. NLTK\n",
      "11. Spacy\n",
      "12. Word2Vec\n",
      "\n",
      "Additionally, the candidate has experience with various other machine learning models and frameworks, including:\n",
      "\n",
      "* SBERT/HuggingFace\n",
      "* OpenAl\n",
      "* Langchain\n",
      "* YOLO\n",
      "* GCP AutoML\n",
      "* Databricks MLOps\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Based on this resume, what machine libraries is the candidate experienced with?\"\n",
    "\n",
    "response1 = chain.invoke(input={'context': context0, 'question': q1})\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85115a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": [\n",
      "        \"Based on this resume, what machine libraries is the candidate experienced with?\"\n",
      "    ],\n",
      "    \"answer\": [\n",
      "        \"Based on the provided context, the candidate has experience with the following machine learning libraries:1. TensorFlow2. PyTorch3. scikit-learn4. Prophet5. Nixtla TimeGPT6. Statsmodels7. Sagemaker DeepAR8. Catboost9. sklearn10. NLTK11. Spacy12. Word2VecAdditionally, the candidate has experience with various other machine learning models and frameworks, including:* SBERT/HuggingFace* OpenAl* Langchain* YOLO* GCP AutoML* Databricks MLOps\"\n",
      "    ],\n",
      "    \"contexts\": [\n",
      "        [\n",
      "            \"Role: you are a generic recruiter reading a candidate's resume.\"\n",
      "        ]\n",
      "    ],\n",
      "    \"ground_truth\": [\n",
      "        \"Tensorflow, PyTorch, scikit-learn, Prophet, Nixtla TimeGPT, Statsmodels, Sagemaker DeepAR, Catboost, sklearn, NLTK, Spacy, Word2Vec, SBERT/HuggingFace, OpenAI, Langchain, YOLO,  Deep learning, Reinforcement Learning, RAG Systems\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_samples = {\n",
    "    'question': [\n",
    "         #q0, \n",
    "         q1\n",
    "    ],\n",
    "    'answer': [\n",
    "         #response0.replace(\"\\n\", \"\"), \n",
    "         response1.replace(\"\\n\", \"\")\n",
    "\n",
    "    ],\n",
    "    'contexts': [\n",
    "        [\n",
    "            context0\n",
    "        ],\n",
    "        #[\n",
    "        #    context0\n",
    "        #]\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "        #'The candidate has a total of 18.5 years of experience.',\n",
    "        'Tensorflow, PyTorch, scikit-learn, Prophet, Nixtla TimeGPT, Statsmodels, Sagemaker DeepAR, Catboost, sklearn, NLTK, Spacy, Word2Vec, SBERT/HuggingFace, OpenAI, Langchain, YOLO,  Deep learning, Reinforcement Learning, RAG Systems'\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "json_formatted_string = json.dumps(data_samples, indent=4)\n",
    "print(json_formatted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d88668c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Ensure deterministic output for evaluation\n",
    "llm_eval = ChatOllama(model=local_llm, temperature=0)\n",
    "evaluator_llm = LangchainLLMWrapper(llm_eval)\n",
    "evaluator_embed = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "\n",
    "# Test if embeddings wrapper works\n",
    "try:\n",
    "    test_embedding = evaluator_embed.embed_query(\"test text\")\n",
    "    print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Embeddings wrapper error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6261677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ee960333894da8bf4a2105314473a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[1]: OutputParserException(Invalid json output: What machine learning libraries and frameworks does the candidate have experience with?\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE )\n",
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': nan, 'answer_relevancy': nan, 'answer_correctness': nan, 'semantic_similarity': 0.7626}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate using Ragas\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        #context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        #context_recall\n",
    "        answer_correctness,\n",
    "        answer_similarity,\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embed,\n",
    "    run_config=RunConfig(timeout=300, \n",
    "                         max_retries=3, # Reduce retries initially\n",
    "                         max_wait=300, \n",
    "                         log_tenacity=True # Enable logging for debugging\n",
    "    ),\n",
    "    raise_exceptions=False # Don't stop on first error\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33424c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
