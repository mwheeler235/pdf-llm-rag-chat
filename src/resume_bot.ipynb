{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33583d94-e35c-49bf-9bd9-cc4702b4573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfb1a694-ee9b-493a-8dc2-6a5dcffc6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../pdf/Mateo Wheeler Resume v2.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4de16b3c-6566-41d7-b78c-65a3a2167774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6828"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b2137c-9ae8-445e-830f-4ca8ebb62f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "#Split and chunk the data\n",
    "chunk_size = 150\n",
    "chunk_overlap = 75\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Add the chunks to vector database, which uses nomic for model embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "                                    documents=chunks, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "                                    collection_name=\"local-rag\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e777e083-731e-4c6c-8e15-20455cd84035",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"As a recruiter, you need to evaluate if a candidate is a good fit for a role. \n",
    "                If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "                Question: {question}\n",
    "           \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6917f39f-b4b3-4453-a07b-47d76e24bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy company_description and job_description from LinkedIn job posts\n",
    "company_description = \"\"\"Sift equips healthcare providers and revenue cycle managers with a complete payments analytics platform making it easy to visualize and understand payment trends, prioritize RCM workflows and accelerate cash flow.\n",
    "Sift improves data clarity and optimizes the financial performance of the entire revenue cycle continuum. Meaningful insights help reduce denials, increase patient payments, maximize reimbursements and reduce time and cost to collect.\n",
    "\"\"\"\n",
    "\n",
    "job_description = \"\"\"Five (5) plus years of experience working with large disparate data sets, using machine learning to derive healthcare insights\n",
    "Experience with deep learning / GenAI\n",
    "NLP, LLMs, Transformers, LSTM, GNNs, etc.\n",
    "Experience with productionization is a plus.\n",
    "Experience with the following concepts: tree-based models (Random Forest, GBM, XGBoost, etc.), clustering models (K-means, KNN, KAMILA, DBSCAN, etc.), forecasting (ARIMA, Prophet, etc.), regression, anomaly detection, etc.\n",
    "Experience working with temporal, cross-sectional, and unstructured data\n",
    "Experience with git, including conducting & participating in code reviews\n",
    "Experience with Python and SQL\n",
    "Experience working with healthcare data\n",
    "EMR, Claims, Midcycle Revenue, Clinical or Coding data experience a plus\n",
    "Strong written and oral communication skills\n",
    "Advanced degree (MS or higher) in applied data science, statistics, economics, computer science, computational natural sciences, or a related field\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a19eaae-15d9-485b-bb05-3c3c509f3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, it appears that the candidate has relevant experience in machine learning, deep learning, and natural language processing (NLP), as well as experience with data visualization, productionization, and healthcare data. The job requirements mention a strong background in business analytics, data science, and statistics.\n",
      "\n",
      "The candidate's resume documents skills such as:\n",
      "\n",
      "* Experience with large disparate data sets\n",
      "* Deep learning/GenAI\n",
      "* NLP, LLMs, Transformers, LSTM, GNNs, etc.\n",
      "* Productionization experience\n",
      "* Knowledge of tree-based models (Random Forest, GBM, XGBoost), clustering models (K-means, KNN, DBSCAN), forecasting (ARIMA, Prophet), regression, and anomaly detection\n",
      "\n",
      "The candidate also has strong written and oral communication skills, an advanced degree in a related field, and experience working with healthcare data (EMR, Claims, Midcycle Revenue, Clinical or Coding data).\n",
      "\n",
      "Considering the role of Sift equips healthcare providers and revenue cycle managers with a complete payments analytics platform, it seems that the candidate's skills align well with the job requirements. They appear to have the necessary technical expertise in machine learning, data science, and statistics, as well as experience working with healthcare data.\n",
      "\n",
      "However, without further information about the specific responsibilities and tasks associated with this role, it is difficult to make a definitive evaluation of the candidate's qualifications.\n"
     ]
    }
   ],
   "source": [
    "context = f\"Role: you are a recruiter for {company_description}. The job position requirements are the following:\\\n",
    "            {job_description}\\\n",
    "        \"\n",
    "\n",
    "q = \"Can you evaluate the candidate in this resume document for the role provided?\"\n",
    "\n",
    "response = chain.invoke(input={'context': context, 'question': q})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231a233-ae85-49ce-b868-8738f38d2d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
