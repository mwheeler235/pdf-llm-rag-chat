{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bff0e5-6f62-456d-8de9-66bc964de77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "from ragas import EvaluationDataset, evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_precision, context_recall, Faithfulness\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from datasets import Dataset\n",
    "import time\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87f477-4a21-4956-9390-2a3ea2eb973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = \"../pdf/BILLS-119hr1eh.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ce65b-2aab-456c-a834-29275c0185c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fed48-d424-4c98-90dc-2a052fe543ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and chunk the data\n",
    "chunk_size = 750\n",
    "chunk_overlap = 200\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "# Add the chunks to vector database, which uses nomic for model embeddings\n",
    "vector_db = Chroma.from_documents(\n",
    "                                    documents=chunks, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "                                    collection_name=\"local-rag\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e4f6f-e2dd-49bb-9d69-6bcfe62fda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.2\"\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "#evaluator_llamma= FaithfulnessEvaluator(llm=llm)\n",
    "\n",
    "\n",
    "# Set up a basic PromptTemplate as the backbones of the solution\n",
    "# Ask the system to gather several responses and to limit response to 200 words\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "        template=\"\"\"You are an AI Language model assistant. Your task is to generate three different versions of the given user question \n",
    "        to retrieve relevant documents from a vector database. Please be as concise as possible and limit your response to 200 words or less. \n",
    "        Original question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cffd9-432c-4696-aa09-30ae4934e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a ChatPromptTemplate to initiate a conversation, allowing the System to assume a Role\n",
    "chat_template = \"\"\"Answer the question based only on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(chat_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc31389-97c2-439f-991f-afd27f0243c8",
   "metadata": {},
   "source": [
    "### Context-Driven responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37587d44-6137-4700-80a7-49bfca5883f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = ['Resulting from this Act, which groups would be harmed most?',\\\n",
    "          'Resulting from this Act, which groups would benefit most?']\n",
    "\n",
    "c_list = ['Role: you are a staunch Democrat',\\\n",
    "          'Role: you are a staunch Republican',\\\n",
    "          'Role: you are a US citizen with no political affiliation',\\\n",
    "          'Role: you are a wealthy investor with interests in oil, gas, and mining',\\\n",
    "          'Role: you are a person that enjoys recreating in public lands while living in Colorado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bc488-abd7-4fef-bb83-1b37f1441d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_gen(q, context):\n",
    "    \"\"\"\n",
    "    Invoke the language model chain with a given question and context, \n",
    "    then print the question, context, and the model's response.\n",
    "\n",
    "    Args:\n",
    "        q (str): The question to ask.\n",
    "        context (str): The context or role to provide to the model.\n",
    "    \"\"\"\n",
    "    response = chain.invoke(input={'context': context, 'question': q})\n",
    "    \n",
    "    print('*** \\n')\n",
    "    print(f\"Question - {q}\")\n",
    "    print(f\"Context - {context} \\n\")\n",
    "    print(\"Response: \\n\", response)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def iterate_responses(q_list, c_list):\n",
    "\n",
    "    response_list = []\n",
    "    df_responses = []\n",
    "    \n",
    "    for combo in itertools.product(q_list, c_list):\n",
    "        response = response_gen(q=combo[0], context=combo[1])\n",
    "\n",
    "        data = {\n",
    "        'question': [combo[0]],\n",
    "        'context': [combo[1]],\n",
    "        'response': [response]\n",
    "        }\n",
    "    \n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "        response_list.append(df)\n",
    "\n",
    "    df_responses = pd.concat(response_list)\n",
    "    df_responses.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return df_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb23e4-0444-4a49-9039-309ca564abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list1 = ['Resulting from this Act, which groups would be harmed most?']\n",
    "\n",
    "c_comp_list = ['Role: you are a US citizen with no political affiliation',\\\n",
    "        'Role: you are a staunch Republican',\\\n",
    "        'Role: you are a staunch Republican, at a bar with only 15 seconds to explain your stance on the document',\\\n",
    "        'Role: you are a staunch Republican and Trump Supporter, at a bar with only 15 seconds to explain your stance on the document']\n",
    "\n",
    "df_responses = iterate_responses(q_list=q_list1, c_list=c_comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7b8b0-7fc6-47fb-b300-c9de2a0a86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3636de2c",
   "metadata": {},
   "source": [
    "### Leverage RAGAS for Evaluating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation questions, contexts, and answers\n",
    "eval_questions = [\"Resulting from this Act, which groups would be harmed most?\"]\n",
    "\n",
    "eval_answers = [\n",
    "   \"The people who would be harmed most by this Act are the non-citizen individuals and foreign corporations. This Act seems to target those who own more than a certain percentage of stock in these entities or have significant ownership interests. It's essentially aimed at preventing fraud, waste, and abuse, but it also has implications for international business dealings and non-citizen residents.\"\n",
    "]\n",
    "\n",
    "contexts = [\n",
    "    \"Role: you are a staunch Republican, at a bar with only 15 seconds to explain your stance on the document\"\n",
    "]\n",
    "\n",
    "# pull ground truth from answer with context = 'US citizen with no political affiliation'\n",
    "ground_truth = [\n",
    "   \"Based on the provided text, it appears that the legislation may harm certain groups in the following ways: Foreign nationals: The 'unfair foreign tax' provision may affect foreign nationals who are subject to taxation by a foreign government. However, this is not necessarily a group that would be harmed most. Small businesses: Some provisions, such as the repeal of EPA rules and NHTSA standards, may benefit small businesses by reducing regulations and costs. However, this is not necessarily a group that would be harmed most. Low-income individuals: The legislation includes provisions related to health insurance, such as the 'exchange enrollment verification requirement' and the 'premium adjustment percentage.' These provisions may affect low-income individuals who rely on government-subsidized health insurance plans.\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ce3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = {\n",
    "    'question': [\n",
    "         eval_questions[0]\n",
    "    ],\n",
    "    'answer': [\n",
    "         eval_answers[0]\n",
    "    ],\n",
    "    'contexts': [\n",
    "        [\n",
    "            contexts[0]\n",
    "        ]\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "       'Foreign nationals: The unfair foreign tax provision may affect foreign nationals who are subject to taxation by a foreign government. \\\n",
    "       Small businesses: Some provisions, such as the repeal of EPA rules and NHTSA standards, may benefit small businesses by reducing regulations and costs. However, this is not necessarily a group that would be harmed most. \\\n",
    "       Low-income individuals: The legislation includes provisions related to health insurance, such as the exchange enrollment verification requirement and the premium adjustment percentage. These provisions may affect low-income individuals who rely on government-subsidized health insurance plans. \\\n",
    "       Health care workers: The legislation includes provisions that may impact health care workers, particularly those involved in administering or managing government-subsidized health insurance programs. \\\n",
    "       Clean energy companies: The legislation includes provisions that may impact clean energy companies, particularly those involved in renewable energy projects and environmental regulations.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "json_formatted_string = json.dumps(data_samples, indent=4)\n",
    "print(json_formatted_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67188b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EvaluationDataset standardizes the collected evaluation examples into a structured format\n",
    "# evaluation_dataset = EvaluationDataset.from_list([dataset_dict])\n",
    "# evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e052fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(BaseCallbackHandler):\n",
    "\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        print(f\"**********Prompts*********:\\n {prompts[0]}\\n\\n\")\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        print(f\"**********Response**********:\\n {response}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embed = LangchainEmbeddingsWrapper(\"nomic-embed-text\")\n",
    "\n",
    "# test only one metric for debugging\n",
    "result_faith = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[faithfulness],  # Just one metric\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embed\n",
    ")\n",
    "\n",
    "print(result_faith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9db5c8-357d-4a5a-aa24-ea0fc56dc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Evaluate using Ragas\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embed,\n",
    "    run_config=RunConfig(timeout=300, max_retries=10, max_wait=300, log_tenacity=False),\n",
    "    raise_exceptions=True, \n",
    "    callbacks=[TestCallback()],\n",
    "    column_map = []\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39570800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
